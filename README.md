# Welcome

Welcome to Prompt Engineering Test for Low Parameter LLMs. created by Poyraz GÃ¼ler.

Here we have to main codes separate from each other. For users who have access to powerful hardware that could run 4bit 8Billion param models we recommend run-server-gpu.py For users who don't wish to run the models locally we recommend run-api.py which uses GROQ api to run llama8B. Notice that run-api only tests prompts on 1 model and does not have a way to add your own model.

Detailed info on our test results and how to use it yourself can be reached through  the readme.md file inside the project.

# the interface
here you can see the expected interface for our prompt engineering tool.
<img width="1216" alt="Screenshot 2024-08-09 at 10 44 59" src="https://github.com/user-attachments/assets/33aa49be-5d7b-43c2-8764-b78bccca8ecd">

You can pick your models through the dropbox on top-left corner
<img width="987" alt="Screenshot 2024-08-09 at 10 42 31" src="https://github.com/user-attachments/assets/2a9a9be8-976a-4a6c-bf7a-92d4716b6f9e">
